{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries for web scraping with selenium\n",
    "from selenium import webdriver\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-0eb49b78591d>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:/Users/pillap/Desktop/PSD BACKUP/FlipRobo Projects/chromedriver_win32/chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "#Chrome web driver location provided for selenium automation works \n",
    "driver=webdriver.Chrome(r\"C:/Users/pillap/Desktop/PSD BACKUP/FlipRobo Projects/chromedriver_win32/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.\n",
    "Q2: Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-7c07da90624b>:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search=driver.find_element_by_css_selector(\"input.sugInp\")\n",
      "<ipython-input-12-7c07da90624b>:4: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  location=driver.find_element_by_xpath(\"//div[@class='inpWrap']/input[@name='location']\")\n",
      "<ipython-input-12-7c07da90624b>:6: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  enter=driver.find_element_by_css_selector(\"button.btn\")\n",
      "<ipython-input-12-7c07da90624b>:13: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  Job=driver.find_elements_by_xpath(\"//div[@class='jobTupleHeader']/div[@class='info fleft']/a[@class='title fw500 ellipsis']\")\n",
      "<ipython-input-12-7c07da90624b>:16: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  loc=driver.find_elements_by_css_selector(\"ul.mt-7\")\n",
      "<ipython-input-12-7c07da90624b>:20: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  com=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for “Data Analyst” Job position in “Bangalore” location of details job-title, job-location, company_name, experience for the first 10 job datas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst - Flipkart Analytics</td>\n",
       "      <td>Bangalore/Bengaluru(Bellandur)</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Urgent Openings For Data Analyst / Business An...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Data Analyst(BigId) - Capco - Bangalore</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Capco Technologies Pvt Ltd</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Data Analyst - Database Design/Mining</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Opportunity For Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "      <td>Botree Software International Private Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Pioneer Business Solutions</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Pioneer Business Solutions</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                  Data Analyst - Flipkart Analytics   \n",
       "1  Urgent Openings For Data Analyst / Business An...   \n",
       "2   Business Data Analyst(BigId) - Capco - Bangalore   \n",
       "3     Business Data Analyst - Database Design/Mining   \n",
       "4              Opportunity For Business Data Analyst   \n",
       "5                                       Data Analyst   \n",
       "6                                       Data Analyst   \n",
       "7                                       Data Analyst   \n",
       "8                                Senior Data Analyst   \n",
       "9                                    Sr Data Analyst   \n",
       "\n",
       "                              Job_Location  \\\n",
       "0           Bangalore/Bengaluru(Bellandur)   \n",
       "1                      Bangalore/Bengaluru   \n",
       "2                      Bangalore/Bengaluru   \n",
       "3                      Bangalore/Bengaluru   \n",
       "4  Bangalore/Bengaluru, Mumbai (All Areas)   \n",
       "5                      Bangalore/Bengaluru   \n",
       "6                      Bangalore/Bengaluru   \n",
       "7                      Bangalore/Bengaluru   \n",
       "8                      Bangalore/Bengaluru   \n",
       "9                      Bangalore/Bengaluru   \n",
       "\n",
       "                                    Company_Name Experience  \n",
       "0                                       Flipkart    0-3 Yrs  \n",
       "1                                       Flipkart    1-6 Yrs  \n",
       "2                     Capco Technologies Pvt Ltd    3-8 Yrs  \n",
       "3                                    AugmatrixGo    2-5 Yrs  \n",
       "4  Botree Software International Private Limited    3-6 Yrs  \n",
       "5                              Applied Materials    0-3 Yrs  \n",
       "6                                          Shell    5-8 Yrs  \n",
       "7                                          Shell   5-10 Yrs  \n",
       "8                     Pioneer Business Solutions   6-11 Yrs  \n",
       "9                     Pioneer Business Solutions    3-8 Yrs  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting into naukri web site through driver.get\n",
    "driver.get('https://www.naukri.com/')\n",
    "#finding the tag of search portion\n",
    "search=driver.find_element_by_css_selector(\"input.sugInp\")\n",
    "#sending the keys for data analyst\n",
    "search.send_keys('data analyst')\n",
    "#finding the tag of location\n",
    "location=driver.find_element_by_xpath(\"//div[@class='inpWrap']/input[@name='location']\")\n",
    "#providing the search key word for location through keys\n",
    "location.send_keys('Bangalore')\n",
    "#locating the click button tag and send the click() action on it\n",
    "enter=driver.find_element_by_css_selector(\"button.btn\")\n",
    "enter.click()\n",
    "#by providing the 3 sec delay to allow the website to open completely\n",
    "time.sleep(3)\n",
    "# creating the empty lists\n",
    "Loc=[]\n",
    "job=[]\n",
    "Exp=[]\n",
    "Com=[]\n",
    "#finding the tag for Job title and store the text in job list through for loop\n",
    "Job=driver.find_elements_by_xpath(\"//div[@class='jobTupleHeader']/div[@class='info fleft']/a[@class='title fw500 ellipsis']\")\n",
    "for i in Job:\n",
    "    job.append(i.text)\n",
    "loc=driver.find_elements_by_css_selector(\"ul.mt-7\")\n",
    "for m in loc:\n",
    "    Loc.append(m.text.split('\\n')[2])\n",
    "    Exp.append(m.text.split('\\n')[0])\n",
    "com=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in com:\n",
    "    Com.append(i.text)\n",
    "Details=pd.DataFrame({'Job_Title':job[:10], 'Job_Location':Loc[:10], 'Company_Name':Com[:10], 'Experience':Exp[:10]})\n",
    "print('Data for “Data Analyst” Job position in “Bangalore” location of details job-title, job-location, company_name, experience for the first 10 job datas')\n",
    "Details    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-66d5caa32cfc>:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search=driver.find_element_by_css_selector(\"input.sugInp\")\n",
      "<ipython-input-13-66d5caa32cfc>:4: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  location=driver.find_element_by_xpath(\"//div[@class='inpWrap']/input[@name='location']\")\n",
      "<ipython-input-13-66d5caa32cfc>:6: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  enter=driver.find_element_by_css_selector(\"button.btn\")\n",
      "<ipython-input-13-66d5caa32cfc>:13: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  Job=driver.find_elements_by_xpath(\"//div[@class='jobTupleHeader']/div[@class='info fleft']/a[@class='title fw500 ellipsis']\")\n",
      "<ipython-input-13-66d5caa32cfc>:16: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  loc=driver.find_elements_by_css_selector(\"ul.mt-7\")\n",
      "<ipython-input-13-66d5caa32cfc>:19: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  com=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for “Data Analyst” Job position in “Bangalore” location of details job-title, job-location, company_name, experience for the first 10 job datas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Forecasting Analyst/ Data Scientist (US Client)</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Concentrix Daksh Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Oracle India Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru(Sadashiva Nagar)</td>\n",
       "      <td>Convergence Infotech Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist | Fortune 500 Supermarke...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TALENT500 TECH (INDIA) PRIVATE LIMITED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>TransOrg Solutions Services (P) Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist / Tech Lead - SQL / Pyth...</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Exploro Solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Looking For Senior Data Scientist Immediate Jo...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0    Forecasting Analyst/ Data Scientist (US Client)   \n",
       "1                                     Data Scientist   \n",
       "2                              Senior Data Scientist   \n",
       "3  Senior Data Scientist | Fortune 500 Supermarke...   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                                Lead Data Scientist   \n",
       "8  Senior Data Scientist / Tech Lead - SQL / Pyth...   \n",
       "9  Looking For Senior Data Scientist Immediate Jo...   \n",
       "\n",
       "                                        Job_Location  \\\n",
       "0              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2               Bangalore/Bengaluru(Sadashiva Nagar)   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "8                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                              Company_Name  \n",
       "0                Concentrix Daksh Services  \n",
       "1                   Oracle India Pvt. Ltd.  \n",
       "2                 Convergence Infotech Ltd  \n",
       "3   TALENT500 TECH (INDIA) PRIVATE LIMITED  \n",
       "4                                     Visa  \n",
       "5                                     Visa  \n",
       "6                                     Visa  \n",
       "7     TransOrg Solutions Services (P) Ltd.  \n",
       "8                        Exploro Solutions  \n",
       "9  Mount Talent Consulting Private Limited  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sending requests to naukri website\n",
    "driver.get('https://www.naukri.com/')\n",
    "#finding the tag for search column\n",
    "search=driver.find_element_by_css_selector(\"input.sugInp\")\n",
    "#sending keys to search\n",
    "search.send_keys('Data Scientist')\n",
    "#finding the location tag\n",
    "location=driver.find_element_by_xpath(\"//div[@class='inpWrap']/input[@name='location']\")\n",
    "location.send_keys('Bangalore')\n",
    "# fetching the click button tag\n",
    "enter=driver.find_element_by_css_selector(\"button.btn\")\n",
    "enter.click()\n",
    "time.sleep(5)\n",
    "#sleep will pause the program for 5 sec to allow the website to open completly\n",
    "Loc=[]\n",
    "job=[]\n",
    "Exp=[]\n",
    "Com=[]\n",
    "#finding the joib description tag \n",
    "Job=driver.find_elements_by_xpath(\"//div[@class='jobTupleHeader']/div[@class='info fleft']/a[@class='title fw500 ellipsis']\")\n",
    "for i in Job:\n",
    "    job.append(i.text)\n",
    "#locating the location tag\n",
    "loc=driver.find_elements_by_css_selector(\"ul.mt-7\")\n",
    "for m in loc:\n",
    "    Loc.append(m.text.split('\\n')[2])\n",
    "#finding the company name tag\n",
    "com=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in com:\n",
    "    Com.append(i.text)\n",
    "#constructing of data frame with the scrapped data\n",
    "Details=pd.DataFrame({'Job_Title':job[:10], 'Job_Location':Loc[:10], 'Company_Name':Com[:10]})\n",
    "print('Data for “Data Analyst” Job position in “Bangalore” location of details job-title, job-location, company_name, experience for the first 10 job datas')\n",
    "Details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-a169620d6ab4>:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search=driver.find_element_by_css_selector(\"input.sugInp\")\n",
      "<ipython-input-14-a169620d6ab4>:4: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  enter=driver.find_element_by_css_selector(\"button.btn\")\n",
      "<ipython-input-14-a169620d6ab4>:7: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  lfilter=driver.find_element_by_xpath(\"//p[@class='grey-text lH20 fleft ml-8 txtLbl']/span[@title='Delhi / NCR']\")\n",
      "<ipython-input-14-a169620d6ab4>:10: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  pfilter=driver.find_element_by_xpath(\"//p[@class='grey-text lH20 fleft ml-8 txtLbl']/span[@title='3-6 Lakhs']\")\n",
      "<ipython-input-14-a169620d6ab4>:17: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  title=driver.find_elements_by_xpath(\"//div[@class='info fleft']/a[@class='title fw500 ellipsis']\")\n",
      "<ipython-input-14-a169620d6ab4>:20: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  loc=driver.find_elements_by_xpath(\"//ul[@class='mt-7']/li[3]\")\n",
      "<ipython-input-14-a169620d6ab4>:23: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  com=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a[@class='subTitle ellipsis fleft']\")\n",
      "<ipython-input-14-a169620d6ab4>:26: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  exp=driver.find_elements_by_xpath(\"//ul[@class='mt-7']/li[@class='fleft grey-text br2 placeHolderLi experience']\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Comapny_Nmae</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kochi/Cochin, Kolkata, Hyderabad/Secunderabad,...</td>\n",
       "      <td>Think i</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job Opportunity || Data Scientist || HCL Techn...</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida(Sector-126 Noida)</td>\n",
       "      <td>MoMagic Technologies Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida(Sector-126 Noida)</td>\n",
       "      <td>MoMagic Technologies Pvt. Ltd.</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Urgent Hiring || Data Scientist || Delhi</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Shriram Automall India Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Gurgaon/Gurugram</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>SVK Global Solutions Private Limited</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Immediate requirement For Data Scientist</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...</td>\n",
       "      <td>CALIBEHR BUSINESS SUPPORT SERVICES PRIVATE LIM...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist Internship</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>iHackers Inc</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Project Manager | Team Leader | Senior Data Sc...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Tidyquant (OPC) Private Limited</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_Title  \\\n",
       "0                                      Data Scientist   \n",
       "1   Job Opportunity || Data Scientist || HCL Techn...   \n",
       "2                                      Data Scientist   \n",
       "3                                      Data Scientist   \n",
       "4            Urgent Hiring || Data Scientist || Delhi   \n",
       "5                                      Data Scientist   \n",
       "6                                      Data Scientist   \n",
       "7            Immediate requirement For Data Scientist   \n",
       "8                           Data Scientist Internship   \n",
       "9                                      Data Scientist   \n",
       "10  Project Manager | Team Leader | Senior Data Sc...   \n",
       "\n",
       "                                         Job_location  \\\n",
       "0   Kochi/Cochin, Kolkata, Hyderabad/Secunderabad,...   \n",
       "1                                         Delhi / NCR   \n",
       "2                             Noida(Sector-126 Noida)   \n",
       "3                             Noida(Sector-126 Noida)   \n",
       "4                                         Delhi / NCR   \n",
       "5                             Noida, Gurgaon/Gurugram   \n",
       "6                                               Noida   \n",
       "7   Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...   \n",
       "8                                           New Delhi   \n",
       "9       Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "10                                             Remote   \n",
       "\n",
       "                                         Comapny_Nmae Experience  \n",
       "0                                             Think i    0-2 Yrs  \n",
       "1                                    HCL Technologies    4-7 Yrs  \n",
       "2                      MoMagic Technologies Pvt. Ltd.    4-6 Yrs  \n",
       "3                      MoMagic Technologies Pvt. Ltd.    4-6 Yrs  \n",
       "4                      Shriram Automall India Limited    2-7 Yrs  \n",
       "5      Optum Global Solutions (India) Private Limited    2-6 Yrs  \n",
       "6                SVK Global Solutions Private Limited   6-10 Yrs  \n",
       "7   CALIBEHR BUSINESS SUPPORT SERVICES PRIVATE LIM...    2-7 Yrs  \n",
       "8                                        iHackers Inc    0-1 Yrs  \n",
       "9                                   Fractal Analytics    3-7 Yrs  \n",
       "10                    Tidyquant (OPC) Private Limited    2-7 Yrs  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#opening the naukri website through the chromedriver by get method\n",
    "driver.get('https://www.naukri.com/')\n",
    "#finding the search tag in the html\n",
    "search=driver.find_element_by_css_selector(\"input.sugInp\")\n",
    "#sending required keys text to the search tag\n",
    "search.send_keys('Data Scientist')\n",
    "#finding the click button\n",
    "enter=driver.find_element_by_css_selector(\"button.btn\")\n",
    "enter.click()\n",
    "#pausing the programme for 2 sec to allow the website to open completely\n",
    "time.sleep(2)\n",
    "#finding the location filter for delhi\n",
    "lfilter=driver.find_element_by_xpath(\"//p[@class='grey-text lH20 fleft ml-8 txtLbl']/span[@title='Delhi / NCR']\")\n",
    "#applying click for the delhi location \n",
    "lfilter.click()\n",
    "#puasing the programme for 2 sec\n",
    "time.sleep(2)\n",
    "#finding the package filter for 3-6 lakhs\n",
    "pfilter=driver.find_element_by_xpath(\"//p[@class='grey-text lH20 fleft ml-8 txtLbl']/span[@title='3-6 Lakhs']\")\n",
    "#click for the filtered package\n",
    "pfilter.click()\n",
    "#pausing it for 2 sec\n",
    "time.sleep(2)\n",
    "#defining the reuqired lists\n",
    "Title=[]\n",
    "Loc=[]\n",
    "Com=[]\n",
    "Exp=[]\n",
    "# fetching the designation data tag from html\n",
    "title=driver.find_elements_by_xpath(\"//div[@class='info fleft']/a[@class='title fw500 ellipsis']\")\n",
    "for i in title:\n",
    "    Title.append(i.text)\n",
    "#getting the location data related tag\n",
    "loc=driver.find_elements_by_xpath(\"//ul[@class='mt-7']/li[3]\")\n",
    "for i in loc:\n",
    "    Loc.append(i.text)\n",
    "#finding the company names data tag\n",
    "com=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a[@class='subTitle ellipsis fleft']\")\n",
    "for i in com:\n",
    "    Com.append(i.text)\n",
    "#getting the data from the experience tags in html\n",
    "exp=driver.find_elements_by_xpath(\"//ul[@class='mt-7']/li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for i in exp:\n",
    "    Exp.append(i.text)\n",
    "#orginising the data in data frame\n",
    "Details=pd.DataFrame({'Job_Title':Title,'Job_location':Loc,'Comapny_Nmae':Com,'Experience':Exp}).loc[:10]\n",
    "Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes: To scrape the data you have to go through following steps:\n",
    "\n",
    "Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "After scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it.\n",
    "Now scrape data from this page as usual\n",
    "Repeat this until you get data for 100 sunglasses. Note: That all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-5938ec24bf33>:3: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search=driver.find_element_by_class_name(\"_3704LK\")\n",
      "<ipython-input-18-5938ec24bf33>:5: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  button=driver.find_element_by_css_selector(\"button.L0Z3Pu\")\n",
      "<ipython-input-18-5938ec24bf33>:14: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  brand=driver.find_elements_by_css_selector(\"div._2WkVRV\")\n",
      "<ipython-input-18-5938ec24bf33>:20: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  des=driver.find_elements_by_class_name(\"IRpwTa\")\n",
      "<ipython-input-18-5938ec24bf33>:26: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  pri=driver.find_elements_by_xpath(\"//div[@class='_25b18c']/div[@class='_30jeq3']\")\n",
      "<ipython-input-18-5938ec24bf33>:28: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  if len(driver.find_element_by_class_name(\"_25b18c\").text)!=len(driver.find_element_by_class_name(\"_30jeq3\").text):\n",
      "<ipython-input-18-5938ec24bf33>:32: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  per=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
      "<ipython-input-18-5938ec24bf33>:38: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  pn=driver.find_element_by_css_selector(\"div._2MImiq\")\n",
      "<ipython-input-18-5938ec24bf33>:44: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  next_page=driver.find_element_by_xpath(\"//div/nav/a[11]\")\n",
      "<ipython-input-18-5938ec24bf33>:41: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  next_page=driver.find_element_by_xpath(\"//div/nav/a[12]\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping of 100 sunglasses details from flipkart which include Brand, Product Description, Price, Offer Percentage\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Offer_Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Aviator Sunglasses (53)</td>\n",
       "      <td>₹999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>Polarized</td>\n",
       "      <td>₹999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹513</td>\n",
       "      <td>35% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹264</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹200</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection</td>\n",
       "      <td>₹711</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>Mirrored Round Sunglasses (53)</td>\n",
       "      <td>₹263</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹294</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection</td>\n",
       "      <td>₹345</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (61)</td>\n",
       "      <td>₹698</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                               Product Description Price  \\\n",
       "0   VINCENT CHASE             UV Protection Aviator Sunglasses (53)  ₹999   \n",
       "1   VINCENT CHASE                                         Polarized  ₹999   \n",
       "2        Fastrack  UV Protection Rectangular Sunglasses (Free Size)  ₹513   \n",
       "3       Elligator               UV Protection Round Sunglasses (54)  ₹264   \n",
       "4          PIRASO             UV Protection Aviator Sunglasses (54)  ₹200   \n",
       "..            ...                                               ...   ...   \n",
       "95      ROYAL SON                                     UV Protection  ₹711   \n",
       "96      Elligator                    Mirrored Round Sunglasses (53)  ₹263   \n",
       "97      Elligator             UV Protection Aviator Sunglasses (55)  ₹294   \n",
       "98          NuVew                                     UV Protection  ₹345   \n",
       "99         AISLIN            UV Protection Wayfarer Sunglasses (61)  ₹698   \n",
       "\n",
       "   Offer_Percentage  \n",
       "0           50% off  \n",
       "1           50% off  \n",
       "2           35% off  \n",
       "3           89% off  \n",
       "4           87% off  \n",
       "..              ...  \n",
       "95          64% off  \n",
       "96          89% off  \n",
       "97          88% off  \n",
       "98          62% off  \n",
       "99          74% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#opening the flipkart website by chrome driver\n",
    "driver.get('https://www.flipkart.com/')\n",
    "#finding the search column tag\n",
    "search=driver.find_element_by_class_name(\"_3704LK\")\n",
    "#entering the SunGlasses key word\n",
    "search.send_keys(\"sunglasses\")\n",
    "#finding the click buton tag\n",
    "button=driver.find_element_by_css_selector(\"button.L0Z3Pu\")\n",
    "button.click()\n",
    "time.sleep(2)\n",
    "#defining the required empty lists\n",
    "Brand=[]\n",
    "Des=[]\n",
    "Pri=[]\n",
    "Per=[]\n",
    "# while loop will fix the length of each list to 100 data each\n",
    "while len(Des)<100:\n",
    "    #after next page click at the bottom sleep will hold the programme 2 sec to open next page fully\n",
    "    time.sleep(2)\n",
    "    #brand tag\n",
    "    brand=driver.find_elements_by_css_selector(\"div._2WkVRV\")\n",
    "    for i in brand:\n",
    "        Brand.append(i.text)\n",
    "    #product description tag\n",
    "    des=driver.find_elements_by_class_name(\"IRpwTa\")\n",
    "    for i in des:\n",
    "        Des.append(i.text.split(',')[0])\n",
    "    #price data tag\n",
    "    pri=driver.find_elements_by_xpath(\"//div[@class='_25b18c']/div[@class='_30jeq3']\")\n",
    "    for i in pri:\n",
    "        Pri.append(i.text)\n",
    "    #finding the percentage tag\n",
    "    per=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    for i in per:\n",
    "        Per.append(i.text)\n",
    "    #next page tag\n",
    "    pn=driver.find_element_by_css_selector(\"div._2MImiq\")\n",
    "    n=pn.text.split()[1]\n",
    "    # applying click on correct tag by using if condition to get the data from next page if len<=100\n",
    "    if (int(n)!=1):\n",
    "        next_page=driver.find_element_by_xpath(\"//div/nav/a[12]\")\n",
    "        next_page.click()\n",
    "    else:\n",
    "        next_page=driver.find_element_by_xpath(\"//div/nav/a[11]\")\n",
    "        next_page.click()\n",
    "    #forming data frame with scrapped data\n",
    "print(\"Scrapping of 100 sunglasses details from flipkart which include Brand, Product Description, Price, Offer Percentage\")\n",
    "Details=pd.DataFrame({\"Brand\":Brand,\"Product Description\":Des,\"Price\":Pri,\"Offer_Percentage\":Per}).loc[:99]\n",
    "Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/\n",
    "p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-886271352b36>:3: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  allreviews=driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\")\n",
      "<ipython-input-19-886271352b36>:11: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for i in driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\"):\n",
      "<ipython-input-19-886271352b36>:13: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for i in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
      "<ipython-input-19-886271352b36>:15: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for i in driver.find_elements_by_xpath(\"//div/div[@class='t-ZTKy']\"):\n",
      "<ipython-input-19-886271352b36>:17: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  pn=driver.find_element_by_xpath(\"//div[@class='_2MImiq _1Qnn1K']\")\n",
      "<ipython-input-19-886271352b36>:23: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  next_page=driver.find_element_by_xpath(\"//div/nav/a[11]\")\n",
      "<ipython-input-19-886271352b36>:20: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  next_page=driver.find_element_by_xpath(\"//div/nav/a[12]\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPHONE 11 first 100 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Summary</th>\n",
       "      <th>Full_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money *The iPhone 11 of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone. *And I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>The ultimate performance *Camera is superb *Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good *As far as camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating     Review_Summary  \\\n",
       "0       5          Brilliant   \n",
       "1       5     Simply awesome   \n",
       "2       5   Perfect product!   \n",
       "3       5  Worth every penny   \n",
       "4       5          Fabulous!   \n",
       "..    ...                ...   \n",
       "95      5             Super!   \n",
       "96      5          Just wow!   \n",
       "97      5  Terrific purchase   \n",
       "98      5            Awesome   \n",
       "99      3     Decent product   \n",
       "\n",
       "                                          Full_Review  \n",
       "0   The Best Phone for the Money *The iPhone 11 of...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Amazing phone with great cameras and better ba...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  This is my first ever iPhone. *And I truly don...  \n",
       "96  The ultimate performance *Camera is superb *Th...  \n",
       "97  I use a Note10+ and have been using both iOS a...  \n",
       "98  The phone is completely good *As far as camera...  \n",
       "99  Everything u ll like it when u use this iPhone...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sending the iphone 11 link of flipkart website to Chrome drivre\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\")\n",
    "#allowing it sleep for 2 sec to opne the website\n",
    "time.sleep(2)\n",
    "#finding of the reviews tag\n",
    "allreviews=driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\")\n",
    "#click on it\n",
    "allreviews.click()\n",
    "time.sleep(1)\n",
    "R=[]\n",
    "RS=[]\n",
    "RV=[]\n",
    "# excuting the while loop will fix the no of reviews to 100 only\n",
    "while len(R)<=100:\n",
    "    time.sleep(2)\n",
    "    \n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\"):#rating tag\n",
    "        R.append(i.text)\n",
    "    for i in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):#review summary tag\n",
    "        RS.append(i.text)\n",
    "    for i in driver.find_elements_by_xpath(\"//div/div[@class='t-ZTKy']\"):#full review tag\n",
    "        RV.append(i.text.replace('\\n\\n',' *').replace('\\n',' *'))\n",
    "    #next page tag if the no of review not reached to 100\n",
    "    pn=driver.find_element_by_xpath(\"//div[@class='_2MImiq _1Qnn1K']\")\n",
    "    n=pn.text.split()[1]\n",
    "    if (int(n)!=1):\n",
    "        next_page=driver.find_element_by_xpath(\"//div/nav/a[12]\")\n",
    "        next_page.click()\n",
    "    else:\n",
    "        next_page=driver.find_element_by_xpath(\"//div/nav/a[11]\")\n",
    "        next_page.click()\n",
    "# arranging the collected data into a data frame\n",
    "Details=pd.DataFrame({\"Rating\":R,\"Review_Summary\":RS,\"Full_Review\":RV}).loc[:99]\n",
    "print(\"iPHONE 11 first 100 reviews\")\n",
    "Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field. You have to scrape 4 attributes of each sneaker:\n",
    "\n",
    "Brand\n",
    "Product Description\n",
    "Price\n",
    "Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-b49b66f0514c>:3: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search=driver.find_element_by_xpath(\"//div[@class='col-12-12 _2oO9oE']/div[@class='_3OO5Xc']/input[1]\")\n",
      "<ipython-input-11-b49b66f0514c>:5: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  click=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
      "<ipython-input-11-b49b66f0514c>:14: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  a=driver.find_elements_by_css_selector(\"div._25b18c\")\n",
      "<ipython-input-11-b49b66f0514c>:15: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  b=driver.find_elements_by_class_name(\"_30jeq3\")\n",
      "<ipython-input-11-b49b66f0514c>:16: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  c=driver.find_elements_by_class_name(\"_3I9_wc\")\n",
      "<ipython-input-11-b49b66f0514c>:17: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  f=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/div[@class='_2WkVRV']\")\n",
      "<ipython-input-11-b49b66f0514c>:18: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  e=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")\n",
      "<ipython-input-11-b49b66f0514c>:32: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  p=driver.find_element_by_xpath(\"//div[@class='_1AtVbE col-12-12']/div[1]/div[@class='_2MImiq']\")\n",
      "<ipython-input-11-b49b66f0514c>:36: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(\"//nav[@class='yFHi8N']/a[11]\").click()\n",
      "<ipython-input-11-b49b66f0514c>:34: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(\"//nav[@class='yFHi8N']/a[12]\").click()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 sneakers ddetails ffrom FlipKart\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Produt_Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹699</td>\n",
       "      <td>56% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>411 Casual Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VORII</td>\n",
       "      <td>Men's Lace up Walking Shoes Running Shoes Ligh...</td>\n",
       "      <td>₹469</td>\n",
       "      <td>53% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Chevit Latest Fashion Combo Pack of 2 Pairs Ca...</td>\n",
       "      <td>₹699</td>\n",
       "      <td>53% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Birde Trendy Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ESSENCE</td>\n",
       "      <td>New Trendy Sneakers For Men</td>\n",
       "      <td>₹497</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ESSENCE</td>\n",
       "      <td>Trendy Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand                                 Produt_Description Price Discount\n",
       "0   ASTEROID  Original Luxury Branded Fashionable Men's Casu...  ₹499  75% off\n",
       "1     Chevit  Perfect & Affordable Combo Pack of 02 Pairs Sn...  ₹599  66% off\n",
       "2     Chevit  Super Stylish & Trendy Combo Pack of 02 Pairs ...  ₹699  56% off\n",
       "3   Magnolia                                   Sneakers For Men  ₹398  60% off\n",
       "4    Numenzo                        411 Casual Sneakers For Men  ₹499  75% off\n",
       "..       ...                                                ...   ...      ...\n",
       "95     VORII  Men's Lace up Walking Shoes Running Shoes Ligh...  ₹469  53% off\n",
       "96    Chevit  Chevit Latest Fashion Combo Pack of 2 Pairs Ca...  ₹699  53% off\n",
       "97     BIRDE         Birde Trendy Casual Shoes Sneakers For Men  ₹299  40% off\n",
       "98   ESSENCE                        New Trendy Sneakers For Men  ₹497  50% off\n",
       "99   ESSENCE                            Trendy Sneakers For Men  ₹499  50% off\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sending the flipkart link to Chrome web driver to access it\n",
    "driver.get('https://www.flipkart.com/')\n",
    "time.sleep(2)\n",
    "#locating the search tag\n",
    "search=driver.find_element_by_xpath(\"//div[@class='col-12-12 _2oO9oE']/div[@class='_3OO5Xc']/input[1]\")\n",
    "#sending the search key word into search tag\n",
    "search.send_keys(\"sneakers\")\n",
    "#click button tag \n",
    "click=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "click.click()\n",
    "time.sleep(2)\n",
    "#defining the required lists to capture the data\n",
    "B=[]\n",
    "PD=[]\n",
    "P=[]\n",
    "di=[]\n",
    "#while loop to fix the no of iterations\n",
    "while len(B)<=100:\n",
    "    \n",
    "    a=driver.find_elements_by_css_selector(\"div._25b18c\")\n",
    "    b=driver.find_elements_by_class_name(\"_30jeq3\")\n",
    "    c=driver.find_elements_by_class_name(\"_3I9_wc\")\n",
    "    f=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/div[@class='_2WkVRV']\")\n",
    "    e=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")\n",
    "    n=0\n",
    "    m=0\n",
    "    #while loop to capture the data into lists\n",
    "    while n<=39:\n",
    "        B.append(f[n].text)\n",
    "        PD.append(e[n].text)\n",
    "        P.append(b[n].text)\n",
    "        if len(a[n].text)>=9:\n",
    "            d=len(a[n].text)-(len(b[n].text)+len(c[n-m].text))\n",
    "            di.append(a[n].text[-d:])\n",
    "        else:\n",
    "            m=m+1\n",
    "            di.append(\"0% off\")\n",
    "        n=n+1\n",
    "    #next page tag\n",
    "    p=driver.find_element_by_xpath(\"//div[@class='_1AtVbE col-12-12']/div[1]/div[@class='_2MImiq']\")\n",
    "    if int(p.text.split()[1])!=1:\n",
    "        driver.find_element_by_xpath(\"//nav[@class='yFHi8N']/a[12]\").click()\n",
    "    else:\n",
    "        driver.find_element_by_xpath(\"//nav[@class='yFHi8N']/a[11]\").click()\n",
    "    time.sleep(2)\n",
    "#data frame creation with the scrapped data\n",
    "Details=pd.DataFrame({\"Brand\":B, \"Produt_Description\":PD,\"Price\":P,\"Discount\":di}).loc[:99]\n",
    "print(\"100 sneakers ddetails ffrom FlipKart\")\n",
    "Details   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes \n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-0b95d4fc7878>:3: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  a=driver.find_elements_by_xpath(\"//div[@class='vertical-filters-filters']/ul/li[@class='colour-listItem']\")\n",
      "<ipython-input-20-0b95d4fc7878>:12: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(\"//ul[@class='price-list']/li[2]\").click()\n",
      "<ipython-input-20-0b95d4fc7878>:16: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  b=driver.find_elements_by_xpath(\"//ul[@class='results-base']/li/a/div[2]/h3\")\n",
      "<ipython-input-20-0b95d4fc7878>:17: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  d=driver.find_elements_by_xpath(\"//ul[@class='results-base']/li/a/div[2]/h4[1]\")\n",
      "<ipython-input-20-0b95d4fc7878>:18: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  p=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
      "<ipython-input-20-0b95d4fc7878>:25: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  nv=driver.find_element_by_class_name('results-showMoreContainer').text.split()[1]\n",
      "<ipython-input-20-0b95d4fc7878>:29: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(\"//ul[@class='pagination-container']/li[12]\").click()\n",
      "<ipython-input-20-0b95d4fc7878>:27: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(\"//ul[@class='pagination-container']/li[13]\").click()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Details</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>AIR ZOOM PEGASUS Running Shoes</td>\n",
       "      <td>9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>LEBRON WITNESS Basketball Shoe</td>\n",
       "      <td>8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>8099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Zoom Span 4 Running Shoes</td>\n",
       "      <td>7195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Air Zoom Pegasus 38 Shield Run</td>\n",
       "      <td>11495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Textured Sneakers</td>\n",
       "      <td>8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Solid Slip On Shoes</td>\n",
       "      <td>7990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex Mirage Sport Trainers</td>\n",
       "      <td>8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Quilted Leather Pumps</td>\n",
       "      <td>8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Heeled Boots</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                            Details  Price\n",
       "0           Nike     AIR ZOOM PEGASUS Running Shoes   9995\n",
       "1           Nike     LEBRON WITNESS Basketball Shoe   8295\n",
       "2   Hush Puppies  Men Solid Leather Formal Slip-Ons   8099\n",
       "3           Nike      Men Zoom Span 4 Running Shoes   7195\n",
       "4           Nike     Air Zoom Pegasus 38 Shield Run  11495\n",
       "..           ...                                ...    ...\n",
       "95          Puma           Unisex Textured Sneakers   8499\n",
       "96      DAVINCHI                Solid Slip On Shoes   7990\n",
       "97          Puma       Unisex Mirage Sport Trainers   8499\n",
       "98          Geox        Women Quilted Leather Pumps   8999\n",
       "99       Saint G                 Women Heeled Boots   9500\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sending the myntra link to web driver chrome\n",
    "driver.get(\"https://www.myntra.com/shoes\")\n",
    "time.sleep(2)\n",
    "#colour filter tag\n",
    "a=driver.find_elements_by_xpath(\"//div[@class='vertical-filters-filters']/ul/li[@class='colour-listItem']\")\n",
    "#for loop to find the black colour shoes tag\n",
    "for i in a:\n",
    "    if i.text.split()[0]=='Black':\n",
    "        i.click()\n",
    "        break\n",
    "time.sleep(1)\n",
    "#defining required lists\n",
    "B=[]\n",
    "D=[]\n",
    "P=[]\n",
    "driver.find_element_by_xpath(\"//ul[@class='price-list']/li[2]\").click()\n",
    "time.sleep(1)\n",
    "#while loop to iterate for fixed numbers\n",
    "while len(B)<100:\n",
    "    #brand tag data capture\n",
    "    b=driver.find_elements_by_xpath(\"//ul[@class='results-base']/li/a/div[2]/h3\")\n",
    "    #shoes description data capture \n",
    "    d=driver.find_elements_by_xpath(\"//ul[@class='results-base']/li/a/div[2]/h4[1]\")\n",
    "    #shoes prices tag to capture data from it\n",
    "    p=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    #using for loops to load the capture data into the lists\n",
    "    for i in b:\n",
    "        B.append(i.text)\n",
    "    for i in d:\n",
    "        D.append(i.text)\n",
    "    for i in p:\n",
    "        P.append(i.text.replace('Rs.','').split()[0])\n",
    "    #next page tag\n",
    "    nv=driver.find_element_by_class_name('results-showMoreContainer').text.split()[1]\n",
    "    if int(nv)!=1:\n",
    "        driver.find_element_by_xpath(\"//ul[@class='pagination-container']/li[13]\").click()\n",
    "    else:\n",
    "        driver.find_element_by_xpath(\"//ul[@class='pagination-container']/li[12]\").click()\n",
    "    time.sleep(3)\n",
    "#creating a dataframe with the scrapped data\n",
    "Details=pd.DataFrame({\"Brand\":B,\"Details\":D,\"Price\":P})\n",
    "Details\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-ff84090a72f8>:7: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search=driver.find_element_by_xpath(\"//form[@id='nav-search-bar-form']/div[2]/div/input[@id='twotabsearchtextbox']\")\n",
      "<ipython-input-24-ff84090a72f8>:9: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  submit=driver.find_element_by_xpath(\"//div[@class='nav-right']/div\")\n",
      "<ipython-input-24-ff84090a72f8>:11: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath(i).click()\n",
      "<ipython-input-24-ff84090a72f8>:14: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  for i in driver.find_elements_by_css_selector(\"span.a-price-whole\"):\n",
      "<ipython-input-24-ff84090a72f8>:20: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  item=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
      "<ipython-input-24-ff84090a72f8>:35: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  D.append(driver.find_element_by_id(\"productTitle\").text)\n",
      "<ipython-input-24-ff84090a72f8>:36: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  R.append(driver.find_element_by_id(\"acrCustomerReviewText\").text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Details of I5, I7 processor laptops from Amazon\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG Gram 14 Ultra-Light Intel Evo 11th Gen Core...</td>\n",
       "      <td>96 ratings</td>\n",
       "      <td>74,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG Gram 17 Ultra-Light Intel Evo 11th Gen Core...</td>\n",
       "      <td>33 ratings</td>\n",
       "      <td>92,127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 10th Gen Intel Core i5 1...</td>\n",
       "      <td>236 ratings</td>\n",
       "      <td>49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 11th Gen Intel Core i5 1...</td>\n",
       "      <td>123 ratings</td>\n",
       "      <td>66,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Renewed) Dell Latitude (2nd Gen Core i5/4GB R...</td>\n",
       "      <td>1 rating</td>\n",
       "      <td>23,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo Ideapad Gaming 3 11th Gen Intel Core i5...</td>\n",
       "      <td>108 ratings</td>\n",
       "      <td>65,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 2021 11th Gen Intel Core...</td>\n",
       "      <td>39 ratings</td>\n",
       "      <td>49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS VivoBook 14 (2021), Intel Core i5-1135G7 ...</td>\n",
       "      <td>22 ratings</td>\n",
       "      <td>53,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo V14 Intel Core i5 11th Gen 14\" (35.56cm...</td>\n",
       "      <td>3 ratings</td>\n",
       "      <td>48,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acer Aspire 5 11th Gen Core i5 14-inch (35.56 ...</td>\n",
       "      <td>43 ratings</td>\n",
       "      <td>58,113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LG Gram 17 Ultra-Light Intel Evo 11th Gen Core...</td>\n",
       "      <td>33 ratings</td>\n",
       "      <td>1,06,057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LG Gram 14 Ultralight Intel Evo 11th Gen Core ...</td>\n",
       "      <td>40 ratings</td>\n",
       "      <td>87,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HP Pavilion (2021) Intel 11th Gen Core i7 14 i...</td>\n",
       "      <td>536 ratings</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...</td>\n",
       "      <td>1 rating</td>\n",
       "      <td>88,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ASUS TUF Dash F15 (2021) 15.6-inch (39.62 cms)...</td>\n",
       "      <td>15 ratings</td>\n",
       "      <td>93,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ASUS TUF Dash F15 (2021) 15.6-inch (39.62 cms)...</td>\n",
       "      <td>8 ratings</td>\n",
       "      <td>1,09,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" Full ...</td>\n",
       "      <td>4 ratings</td>\n",
       "      <td>98,719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...</td>\n",
       "      <td>6 ratings</td>\n",
       "      <td>1,13,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...</td>\n",
       "      <td>1 rating</td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Microsoft Surface Laptop Studio - 14.4\" Touchs...</td>\n",
       "      <td>1 rating</td>\n",
       "      <td>3,73,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title       Rating     Price\n",
       "0   LG Gram 14 Ultra-Light Intel Evo 11th Gen Core...   96 ratings    74,999\n",
       "1   LG Gram 17 Ultra-Light Intel Evo 11th Gen Core...   33 ratings    92,127\n",
       "2   Lenovo IdeaPad Slim 3 10th Gen Intel Core i5 1...  236 ratings    49,990\n",
       "3   Lenovo IdeaPad Slim 5 11th Gen Intel Core i5 1...  123 ratings    66,990\n",
       "4   (Renewed) Dell Latitude (2nd Gen Core i5/4GB R...     1 rating    23,999\n",
       "5   Lenovo Ideapad Gaming 3 11th Gen Intel Core i5...  108 ratings    65,990\n",
       "6   Lenovo IdeaPad Slim 3 2021 11th Gen Intel Core...   39 ratings    49,990\n",
       "7   ASUS VivoBook 14 (2021), Intel Core i5-1135G7 ...   22 ratings    53,990\n",
       "8   Lenovo V14 Intel Core i5 11th Gen 14\" (35.56cm...    3 ratings    48,990\n",
       "9   Acer Aspire 5 11th Gen Core i5 14-inch (35.56 ...   43 ratings    58,113\n",
       "10  LG Gram 17 Ultra-Light Intel Evo 11th Gen Core...   33 ratings  1,06,057\n",
       "11  LG Gram 14 Ultralight Intel Evo 11th Gen Core ...   40 ratings    87,999\n",
       "12  HP Pavilion (2021) Intel 11th Gen Core i7 14 i...  536 ratings    84,990\n",
       "13  Dell 14 (2021) i7-1195G7 2in1 Touch Screen Lap...     1 rating    88,490\n",
       "14  ASUS TUF Dash F15 (2021) 15.6-inch (39.62 cms)...   15 ratings    93,990\n",
       "15  ASUS TUF Dash F15 (2021) 15.6-inch (39.62 cms)...    8 ratings  1,09,990\n",
       "16  Lenovo Yoga 7 11th Gen Intel Core i7 14\" Full ...    4 ratings    98,719\n",
       "17  ASUS TUF Gaming F17 (2021), 17.3-inch (43.94 c...    6 ratings  1,13,990\n",
       "18  ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...     1 rating    99,990\n",
       "19  Microsoft Surface Laptop Studio - 14.4\" Touchs...     1 rating  3,73,999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the reuired processors tags and store them in a list\n",
    "processor=[\"//li[@id='p_n_feature_thirteen_browse-bin/12598162031']/span\",\"//li[@id='p_n_feature_thirteen_browse-bin/12598163031']/span\"]\n",
    "PR=[]\n",
    "D=[]\n",
    "R=[]\n",
    "# for loop to iterate with the stored processors data from processor list\n",
    "for i in processor:\n",
    "    #sending the amazonlink to driver\n",
    "    driver.get('https://www.amazon.in/')\n",
    "    #locating the search box\n",
    "    search=driver.find_element_by_xpath(\"//form[@id='nav-search-bar-form']/div[2]/div/input[@id='twotabsearchtextbox']\")\n",
    "    #sending the required search words\n",
    "    search.send_keys(\"Laptops\")\n",
    "    #locating the click button tag\n",
    "    submit=driver.find_element_by_xpath(\"//div[@class='nav-right']/div\")\n",
    "    submit.click()\n",
    "    #now capturing the data for selected processors\n",
    "    driver.find_element_by_xpath(i).click()\n",
    "    time.sleep(2)\n",
    "    n=0\n",
    "    for i in driver.find_elements_by_css_selector(\"span.a-price-whole\"):#data from price tag\n",
    "        if n!=10:\n",
    "            PR.append(i.text)\n",
    "        else:\n",
    "            break  \n",
    "        n=n+1\n",
    "    # click tag to reach into the each product window\n",
    "    item=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "    n=0\n",
    "    for i in item:\n",
    "        #fixing the iterations for 10 only\n",
    "        if n==10:\n",
    "            break\n",
    "        else:\n",
    "            #click on the each laptop description to reach into the complete details in new window\n",
    "            i.click()\n",
    "            time.sleep(2)\n",
    "            P=[]\n",
    "            #capturing the windows addresses through window handles\n",
    "            p=driver.window_handles\n",
    "            #stores the winow address in a list\n",
    "            for i in p:\n",
    "                P.append(i)\n",
    "            for i in P:\n",
    "                #switching over the windows with switch to window key words\n",
    "                driver.switch_to.window(i)\n",
    "                # when the window is the required window data will be captured\n",
    "                if i==P[1]:\n",
    "                    #details tag data capture\n",
    "                    D.append(driver.find_element_by_id(\"productTitle\").text)\n",
    "                    #reviews tag data capture\n",
    "                    R.append(driver.find_element_by_id(\"acrCustomerReviewText\").text)\n",
    "                    #current window close after data capture\n",
    "                    driver.close()\n",
    "                    #navagiting to the main window\n",
    "                    driver.switch_to.window(P[0])\n",
    "                #this loop between main window and one child window will continue untill the capture of 10 items\n",
    "                \n",
    "        n=n+1\n",
    "#showing the data in a data frame\n",
    "Details=pd.DataFrame({\"Title\":D,\"Rating\":R,\"Price\":PR})\n",
    "print(\"10 Details of I5, I7 processor laptops from Amazon\")\n",
    "Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. This task will be done in following steps:\n",
    "\n",
    "First get the webpage https://www.ambitionbox.com/\n",
    "Click on the Job option as shown in the image\n",
    "After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter “Data Scientist” and click on search button.\n",
    "You will reach to the following web page click on location and in place of “Search location” enter “Noida” and select location “Noida”.\n",
    "Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-97-bc18a9b2e179>:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  job=driver.find_element_by_xpath(\"//div[@class='sliding-sticky-menu ']/nav/nav/a[6]\")\n",
      "<ipython-input-97-bc18a9b2e179>:4: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  search=driver.find_element_by_xpath(\"//span[@class='twitter-typeahead']/input[@class='input tt-input']\")\n",
      "<ipython-input-97-bc18a9b2e179>:6: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  click=driver.find_element_by_xpath(\"//div[@id='jobSearchPage']/div[2]/div/div/div/div/button\")\n",
      "<ipython-input-97-bc18a9b2e179>:9: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  location=driver.find_element_by_xpath(\"//div[@title='Location' and @class='fitler-text']\")\n",
      "<ipython-input-97-bc18a9b2e179>:11: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  Noida=driver.find_element_by_xpath(\"//div[@class='show-flex']/div[2]/div[2]/div[1]/div[3]/div/div/div[8]/label\")\n",
      "<ipython-input-97-bc18a9b2e179>:16: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  cn=driver.find_elements_by_xpath(\"//div[@class='company-info']\")\n",
      "<ipython-input-97-bc18a9b2e179>:17: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  r=driver.find_elements_by_xpath(\"//div[@class='company-info']/div[@class='rating-wrapper']\")\n",
      "<ipython-input-97-bc18a9b2e179>:18: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  pd=driver.find_elements_by_xpath(\"//div[@class='other-info']/span[1]\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Data Scientist jobs posted in Noida Location through AmbitionBox\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Salaries</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Avg_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 19.4L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 22 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 15.1L</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 60 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 20.8L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 24 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 13.4L</td>\n",
       "      <td>₹ 18.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 45 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 7.2L</td>\n",
       "      <td>₹ 13.3L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 12 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>based on 45 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 6.9L</td>\n",
       "      <td>₹ 11.2L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ernst &amp; Young</td>\n",
       "      <td>based on 26 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 6.0L</td>\n",
       "      <td>₹ 11.1L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>based on 43 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 5.0L</td>\n",
       "      <td>₹ 10.9L</td>\n",
       "      <td>₹ 21.5L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Company              Salaries   Experience Min_Salary  \\\n",
       "0                  Ab Inbev  based on 10 salaries    4 yrs exp    ₹ 15.0L   \n",
       "1                     Optum  based on 22 salaries  3-4 yrs exp    ₹ 11.0L   \n",
       "2         Fractal Analytics  based on 60 salaries  2-4 yrs exp     ₹ 9.0L   \n",
       "3           Tiger Analytics  based on 24 salaries  3-4 yrs exp     ₹ 8.3L   \n",
       "4              UnitedHealth  based on 45 salaries  2-4 yrs exp     ₹ 7.2L   \n",
       "5                   Verizon  based on 14 salaries    4 yrs exp    ₹ 10.0L   \n",
       "6  Ganit Business Solutions  based on 12 salaries    4 yrs exp     ₹ 8.5L   \n",
       "7                  Deloitte  based on 45 salaries  2-4 yrs exp     ₹ 6.9L   \n",
       "8             Ernst & Young  based on 26 salaries  3-4 yrs exp     ₹ 6.0L   \n",
       "9                  Ericsson  based on 43 salaries  3-4 yrs exp     ₹ 5.0L   \n",
       "\n",
       "  Avg_Salary Max_Salary  \n",
       "0    ₹ 19.4L    ₹ 23.0L  \n",
       "1    ₹ 15.1L    ₹ 21.3L  \n",
       "2    ₹ 14.7L    ₹ 20.8L  \n",
       "3    ₹ 13.4L    ₹ 18.5L  \n",
       "4    ₹ 13.3L    ₹ 20.5L  \n",
       "5    ₹ 12.7L    ₹ 21.0L  \n",
       "6    ₹ 12.4L    ₹ 15.0L  \n",
       "7    ₹ 11.2L    ₹ 20.5L  \n",
       "8    ₹ 11.1L    ₹ 20.0L  \n",
       "9    ₹ 10.9L    ₹ 21.5L  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sending the ambition box link to webdriver\n",
    "driver.get(\"https://www.ambitionbox.com/\")\n",
    "#locating the job button\n",
    "job=driver.find_element_by_xpath(\"//div[@class='sliding-sticky-menu ']/nav/nav/a[6]\")\n",
    "job.click()#click on the job button\n",
    "#locating the search column tag\n",
    "search=driver.find_element_by_xpath(\"//span[@class='twitter-typeahead']/input[@class='input tt-input']\")\n",
    "#sending the required key words\n",
    "search.send_keys(\"Data Scientist \")\n",
    "#locating the click button\n",
    "click=driver.find_element_by_xpath(\"//div[@id='jobSearchPage']/div[2]/div/div/div/div/button\")\n",
    "click.click()\n",
    "time.sleep(2)\n",
    "#location filter tag\n",
    "location=driver.find_element_by_xpath(\"//div[@title='Location' and @class='fitler-text']\")\n",
    "location.click()#click on it\n",
    "#locating the Nodia location tag\n",
    "Noida=driver.find_element_by_xpath(\"//div[@class='show-flex']/div[2]/div[2]/div[1]/div[3]/div/div/div[8]/label\")\n",
    "Noida.click()#click on it\n",
    "CN=[]\n",
    "R=[]\n",
    "PD=[]\n",
    "#finding the reuired data tags\n",
    "cn=driver.find_elements_by_xpath(\"//div[@class='company-info']\")\n",
    "r=driver.find_elements_by_xpath(\"//div[@class='company-info']/div[@class='rating-wrapper']\")\n",
    "pd=driver.find_elements_by_xpath(\"//div[@class='other-info']/span[1]\")\n",
    "n=0\n",
    "#while loop to fix the no of iterations\n",
    "while n<10:\n",
    "    \n",
    "    CN.append(cn[n].text.split('\\n')[0])\n",
    "    R.append(r[n].text.replace('\\n',',').split(',')[0])\n",
    "    PD.append(pd[n].text)\n",
    "    n+=1\n",
    "import pandas as pd\n",
    "#creating a data frame with the scrapped data\n",
    "Detail=pd.DataFrame({\"Company_Name\":CN,\"Rating\":R,\"Posted_Days\":PD})\n",
    "print(\"First 10 Data Scientist jobs posted in Noida Location through AmbitionBox\")\n",
    "Details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-98-808c872e257b>:2: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  salary=driver.find_element_by_xpath(\"//div[@class='sliding-sticky-menu ']/nav/nav/a[4]\")\n",
      "<ipython-input-98-808c872e257b>:4: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  role=driver.find_element_by_xpath(\"//input[@type='searchbox' and @ id='jobProfileSearchbox']\")\n",
      "<ipython-input-98-808c872e257b>:7: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  roleclick=driver.find_element_by_xpath(\"//div[@role='presentation' and @class='tt-dataset tt-dataset-job-profile-search']/div[1]/div/div/p[@class='tt_text']\")\n",
      "<ipython-input-98-808c872e257b>:16: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  cdata=driver.find_elements_by_xpath(\"//div[@class='company-info']\")\n",
      "<ipython-input-98-808c872e257b>:25: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  avgctc=driver.find_elements_by_xpath(\"//p[@class='averageCtc']\")\n",
      "<ipython-input-98-808c872e257b>:28: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  minsal=driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[1]\")\n",
      "<ipython-input-98-808c872e257b>:31: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  maxsal=driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[2]\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Data Scientist job details from ambition box which includes company name, no of salaries, required experience, min salary offering, avg salary and max salary offering details as in the above data frame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Salaries</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Min_Salary</th>\n",
       "      <th>Avg_Salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 19.4L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 22 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 15.1L</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 60 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 20.8L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 24 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 13.4L</td>\n",
       "      <td>₹ 18.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 45 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 7.2L</td>\n",
       "      <td>₹ 13.3L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 12 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>based on 45 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 6.9L</td>\n",
       "      <td>₹ 11.2L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ernst &amp; Young</td>\n",
       "      <td>based on 26 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 6.0L</td>\n",
       "      <td>₹ 11.1L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>based on 43 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 5.0L</td>\n",
       "      <td>₹ 10.9L</td>\n",
       "      <td>₹ 21.5L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Company              Salaries   Experience Min_Salary  \\\n",
       "0                  Ab Inbev  based on 10 salaries    4 yrs exp    ₹ 15.0L   \n",
       "1                     Optum  based on 22 salaries  3-4 yrs exp    ₹ 11.0L   \n",
       "2         Fractal Analytics  based on 60 salaries  2-4 yrs exp     ₹ 9.0L   \n",
       "3           Tiger Analytics  based on 24 salaries  3-4 yrs exp     ₹ 8.3L   \n",
       "4              UnitedHealth  based on 45 salaries  2-4 yrs exp     ₹ 7.2L   \n",
       "5                   Verizon  based on 14 salaries    4 yrs exp    ₹ 10.0L   \n",
       "6  Ganit Business Solutions  based on 12 salaries    4 yrs exp     ₹ 8.5L   \n",
       "7                  Deloitte  based on 45 salaries  2-4 yrs exp     ₹ 6.9L   \n",
       "8             Ernst & Young  based on 26 salaries  3-4 yrs exp     ₹ 6.0L   \n",
       "9                  Ericsson  based on 43 salaries  3-4 yrs exp     ₹ 5.0L   \n",
       "\n",
       "  Avg_Salary Max_Salary  \n",
       "0    ₹ 19.4L    ₹ 23.0L  \n",
       "1    ₹ 15.1L    ₹ 21.3L  \n",
       "2    ₹ 14.7L    ₹ 20.8L  \n",
       "3    ₹ 13.4L    ₹ 18.5L  \n",
       "4    ₹ 13.3L    ₹ 20.5L  \n",
       "5    ₹ 12.7L    ₹ 21.0L  \n",
       "6    ₹ 12.4L    ₹ 15.0L  \n",
       "7    ₹ 11.2L    ₹ 20.5L  \n",
       "8    ₹ 11.1L    ₹ 20.0L  \n",
       "9    ₹ 10.9L    ₹ 21.5L  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sending the ambition box link to webdriver\n",
    "driver.get(\"https://www.ambitionbox.com/\")\n",
    "#locating the salary button tag\n",
    "salary=driver.find_element_by_xpath(\"//div[@class='sliding-sticky-menu ']/nav/nav/a[4]\")\n",
    "salary.click()#applying click on the salaries button\n",
    "role=driver.find_element_by_xpath(\"//input[@type='searchbox' and @ id='jobProfileSearchbox']\")#role tag\n",
    "role.send_keys(\"Data Scientist\")#sending the reuired text through keys\n",
    "time.sleep(2)\n",
    "#locating the selected role tag\n",
    "roleclick=driver.find_element_by_xpath(\"//div[@role='presentation' and @class='tt-dataset tt-dataset-job-profile-search']/div[1]/div/div/p[@class='tt_text']\")\n",
    "roleclick.click()#click on it\n",
    "C=[]\n",
    "BS=[]\n",
    "E=[]\n",
    "MS=[]\n",
    "AS=[]\n",
    "MAXS=[]\n",
    "n=0\n",
    "#capturing the data from the obtained tags with for loops\n",
    "cdata=driver.find_elements_by_xpath(\"//div[@class='company-info']\")#company data tag\n",
    "for i in cdata:\n",
    "    #to captured the data for fixed no\n",
    "    if n!=10:\n",
    "        C.append(i.text.split('\\n')[0])\n",
    "        BS.append(i.text.split('\\n')[1])\n",
    "        E.append(i.text.split('\\n')[-1])\n",
    "    else:\n",
    "        break\n",
    "    n+=1\n",
    "avgctc=driver.find_elements_by_xpath(\"//p[@class='averageCtc']\")#average salary data tag\n",
    "for i in avgctc:\n",
    "    AS.append(i.text)\n",
    "minsal=driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[1]\")#minimum salary tag\n",
    "for i in minsal:\n",
    "    MS.append(i.text)\n",
    "maxsal=driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[2]\")#maximum salary tag\n",
    "for i in maxsal:\n",
    "    MAXS.append(i.text)\n",
    "time.sleep(2)\n",
    "import pandas as pd\n",
    "#creating the data frame with the scrapped data\n",
    "Details=pd.DataFrame({\"Company\":C,\"Salaries\":BS,\"Experience\":E,\"Min_Salary\":MS,\"Avg_Salary\":AS, \"Max_Salary\":MAXS})\n",
    "\n",
    "print(\"10 Data Scientist job details from ambition box which includes company name, no of salaries, required experience, min salary offering, avg salary and max salary offering details as in the above data frame\")\n",
    "Details\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
